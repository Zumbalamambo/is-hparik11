{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "smile_cascade = cv2.CascadeClassifier('haarcascade_smile.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('arnie.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_cascade.detectMultiScale(gray, 1.1, 5)\n",
    "\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = img[y:y+h, x:x+w]\n",
    "    eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "    #smiles = smile_cascade.detectMultiScale(roi_color)\n",
    "    \n",
    "    for (ex,ey,ew,eh) in eyes:\n",
    "         cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "    \n",
    "    #for (sx,sy,sw,sh) in smiles:\n",
    "    #     cv2.rectangle(roi_color,(sx,sy),(sx+sw,sy+sh),(255,0,255),2)\n",
    "\n",
    "cv2.imshow('img',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 faces!\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('Image.png')\n",
    "faceCascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "#image = cv2.imread('Image.png')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detect faces in the image\n",
    "faces = faceCascade.detectMultiScale(\n",
    "    gray,\n",
    "    scaleFactor=1.1,\n",
    "    minNeighbors=5,\n",
    "    \n",
    ")\n",
    "\n",
    "print \"Found {0} faces!\".format(len(faces))\n",
    "\n",
    "# Draw a rectangle around the faces\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "    #cv2.imshow(\"Adding faces to traning set...\", img[y: y + h, x: x + w])\n",
    "\n",
    "cv2.imshow(\"Faces found\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = './Images'\n",
    "image_paths = [os.path.join(path, f) for f in os.listdir(path)]     #if f.endswith('.jpg')\n",
    "#print image_path\n",
    "# images will contains face images\n",
    "images = []\n",
    "# labels will contains the label that is assigned to the image\n",
    "labels = []\n",
    "for image_path in image_paths:\n",
    "    # Read the image and convert to grayscale\n",
    "    image_pil = Image.open(image_path).convert('L')\n",
    "    # Convert the image format into numpy array\n",
    "    image = np.array(image_pil, 'uint8')\n",
    "    # Get the label of the image\n",
    "    #nbr = int(os.path.split(image_path)[1].split(\".\")[0].replace(\"subject\", \"\"))\n",
    "    # Detect the face in the image\n",
    "    faces = faceCascade.detectMultiScale(image)\n",
    "    # If face is detected, append the face to images and the label to labels\n",
    "    for (x, y, w, h) in faces:\n",
    "        images.append(image[y: y + h, x: x + w])\n",
    "        #labels.append(nbr)\n",
    "        cv2.imshow(\"Adding faces to traning set...\", image[y: y + h, x: x + w])\n",
    "        cv2.waitKey(50)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = images[1]\n",
    "cv2.imshow(\"sample\",x)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFilter\n",
    "#Read image\n",
    "im = Image.open( 'ankitanarula.jpg' )\n",
    "#Display image\n",
    "im.show()\n",
    "\n",
    "#Applying a filter to the image\n",
    "im_sharp = im.filter( ImageFilter.SHARPEN )\n",
    "#Saving the filtered image to a new file\n",
    "im_sharp.save( 'image_sharpened.jpg', 'JPEG' )\n",
    "\n",
    "#Splitting the image into its respective bands, i.e. Red, Green,\n",
    "#and Blue for RGB\n",
    "r,g,b = im_sharp.split()\n",
    "\n",
    "#Viewing EXIF data embedded in image\n",
    "exif_data = im._getexif()\n",
    "exif_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import glob, os\n",
    "\n",
    "size = 128, 128\n",
    "\n",
    "for infile in glob.glob(\"*.jpg\"):\n",
    "    file, ext = os.path.splitext(infile)\n",
    "    im = Image.open(infile)\n",
    "    im.thumbnail(size, Image.ANTIALIAS)\n",
    "    im.save(file + \".thumbnail\", \"JPEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import sys, math, Image\n",
    "\n",
    "def Distance(p1,p2):\n",
    "  dx = p2[0] - p1[0]\n",
    "  dy = p2[1] - p1[1]\n",
    "  return math.sqrt(dx*dx+dy*dy)\n",
    "\n",
    "def ScaleRotateTranslate(image, angle, center = None, new_center = None, scale = None, resample=Image.BICUBIC):\n",
    "  if (scale is None) and (center is None):\n",
    "    return image.rotate(angle=angle, resample=resample)\n",
    "  nx,ny = x,y = center\n",
    "  sx=sy=1.0\n",
    "  if new_center:\n",
    "    (nx,ny) = new_center\n",
    "  if scale:\n",
    "    (sx,sy) = (scale, scale)\n",
    "  cosine = math.cos(angle)\n",
    "  sine = math.sin(angle)\n",
    "  a = cosine/sx\n",
    "  b = sine/sx\n",
    "  c = x-nx*a-ny*b\n",
    "  d = -sine/sy\n",
    "  e = cosine/sy\n",
    "  f = y-nx*d-ny*e\n",
    "  return image.transform(image.size, Image.AFFINE, (a,b,c,d,e,f), resample=resample)\n",
    "\n",
    "def CropFace(image, eye_left=(0,0), eye_right=(0,0), offset_pct=(0.2,0.2), dest_sz = (70,70)):\n",
    "  # calculate offsets in original image\n",
    "  offset_h = math.floor(float(offset_pct[0])*dest_sz[0])\n",
    "  offset_v = math.floor(float(offset_pct[1])*dest_sz[1])\n",
    "  # get the direction\n",
    "  eye_direction = (eye_right[0] - eye_left[0], eye_right[1] - eye_left[1])\n",
    "  # calc rotation angle in radians\n",
    "  rotation = -math.atan2(float(eye_direction[1]),float(eye_direction[0]))\n",
    "  # distance between them\n",
    "  dist = Distance(eye_left, eye_right)\n",
    "  # calculate the reference eye-width\n",
    "  reference = dest_sz[0] - 2.0*offset_h\n",
    "  # scale factor\n",
    "  scale = float(dist)/float(reference)\n",
    "  # rotate original around the left eye\n",
    "  image = ScaleRotateTranslate(image, center=eye_left, angle=rotation)\n",
    "  # crop the rotated image\n",
    "  crop_xy = (eye_left[0] - scale*offset_h, eye_left[1] - scale*offset_v)\n",
    "  crop_size = (dest_sz[0]*scale, dest_sz[1]*scale)\n",
    "  image = image.crop((int(crop_xy[0]), int(crop_xy[1]), int(crop_xy[0]+crop_size[0]), int(crop_xy[1]+crop_size[1])))\n",
    "  # resize it\n",
    "  image = image.resize(dest_sz, Image.ANTIALIAS)\n",
    "  return image\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  image =  Image.open(\"arnie.jpg\")\n",
    "  CropFace(image, eye_left=(252,364), eye_right=(420,366), offset_pct=(0.1,0.1), dest_sz=(200,200)).save(\"arnie_10_10_200_200.jpg\")\n",
    "  CropFace(image, eye_left=(252,364), eye_right=(420,366), offset_pct=(0.2,0.2), dest_sz=(200,200)).save(\"arnie_20_20_200_200.jpg\")\n",
    "  CropFace(image, eye_left=(252,364), eye_right=(420,366), offset_pct=(0.3,0.3), dest_sz=(200,200)).save(\"arnie_30_30_200_200.jpg\")\n",
    "  CropFace(image, eye_left=(252,364), eye_right=(420,366), offset_pct=(0.2,0.2)).save(\"arnie_20_20_70_70.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
