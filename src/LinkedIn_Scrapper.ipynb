{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import re\n",
    "import os,sys\n",
    "import time\n",
    "from datetime import date\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except:\n",
    "    import pickle\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Gender Predictor File to predict Gender of LinkedIn Profiles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load Gender_Prediction.py\n",
    "\n",
    "# Import Libraries\n",
    "\n",
    "import os\n",
    "import re\n",
    "import urllib2\n",
    "from zipfile import ZipFile\n",
    "import csv\n",
    "import cPickle as pickle\n",
    "\n",
    "def downloadNames():\n",
    "    u = urllib2.urlopen('https://www.ssa.gov/oact/babynames/names.zip')\n",
    "    localFile = open('names.zip', 'w')\n",
    "    localFile.write(u.read())\n",
    "    localFile.close()\n",
    "\n",
    "def getNameList():\n",
    "    if not os.path.exists('names.pickle'):\n",
    "        print 'names.pickle does not exist, generating'\n",
    "        \n",
    "        # https://www.ssa.gov/oact/babynames/names.zip\n",
    "        \n",
    "        if not os.path.exists('names.zip'):\n",
    "            print 'names.zip does not exist, downloading from github'\n",
    "            downloadNames()\n",
    "        else:\n",
    "            print 'names.zip exists, not downloading'\n",
    "        \n",
    "        print 'Extracting names from names.zip'  \n",
    "        \n",
    "        namesDict=extractNamesDict()\n",
    "        \n",
    "        maleNames=list()\n",
    "        femaleNames=list()\n",
    "        \n",
    "        print 'Sorting Names'\n",
    "        \n",
    "        for name in namesDict:\n",
    "            counts=namesDict[name]\n",
    "            tuple=(name,counts[0],counts[1])\n",
    "            if counts[0]>counts[1]:\n",
    "                maleNames.append(tuple)\n",
    "            elif counts[1]>counts[0]:\n",
    "                femaleNames.append(tuple)\n",
    "        \n",
    "        names=(maleNames,femaleNames)\n",
    "        \n",
    "        print 'Saving names.pickle'\n",
    "        fw=open('names.pickle','wb')\n",
    "        pickle.dump(names,fw,-1)\n",
    "        fw.close()\n",
    "        print 'Saved names.pickle'\n",
    "    else:\n",
    "        print 'names.pickle exists, loading data'\n",
    "        f=open('names.pickle','rb')\n",
    "        names=pickle.load(f)\n",
    "        print 'names.pickle loaded'\n",
    "        \n",
    "    print '%d male names loaded, %d female names loaded'%(len(names[0]),len(names[1]))\n",
    "    \n",
    "    return names[0],names[1]\n",
    "\n",
    "def extractNamesDict():\n",
    "    zf=ZipFile('names.zip', 'r')\n",
    "    filenames=zf.namelist()\n",
    "    \n",
    "    names=dict()\n",
    "    genderMap={'M':0,'F':1}\n",
    "    \n",
    "    for filename in filenames:\n",
    "        fp = zf.open(filename,'rU')\n",
    "        rows=csv.reader(fp, delimiter=',', dialect=csv.excel_tab)\n",
    "        try:\n",
    "            for row in rows:\n",
    "            #print name,row[1]\n",
    "                try:\n",
    "                    name=row[0].upper()\n",
    "                    gender=genderMap[row[1]]\n",
    "                    count=int(row[2])\n",
    "\n",
    "                    if not names.has_key(name):\n",
    "                        names[name]=[0,0]\n",
    "\n",
    "                    names[name][gender]=names[name][gender]+count\n",
    "                except:\n",
    "                    pass\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "        fp.close()\n",
    "        \n",
    "        print '\\tImported %s'%filename\n",
    "    return names\n",
    "\n",
    "\n",
    "def find_gender_from_first_name(name):\n",
    "    if name.upper() in new_male_list:\n",
    "        return \"Male\"\n",
    "    elif name.upper() in new_female_list:\n",
    "        return \"Female\"\n",
    "    else:\n",
    "        return \"Unknown\"    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "\tmale_names, female_names = getNameList()\n",
    "\tnew_male_list = []\n",
    "\tnew_female_list = []\n",
    "\n",
    "\tfor index,name in enumerate(male_names):\n",
    "\t\ttry:\n",
    "\t\t    if (name[1]/name[2])>=4:\n",
    "\t\t        new_male_list.append(name[0])\n",
    "\t\texcept:\n",
    "\t\t    new_male_list.append(name[0])\n",
    "\t\t    \n",
    "\t#print \"Total number of Male Names after is %d.\" %len(new_male_list)\t\n",
    "\t\n",
    "\t\n",
    "\tfor index,name in enumerate(female_names):\n",
    "\t\ttry:\n",
    "\t\t    if (name[2]/name[1])>=4:\n",
    "\t\t        new_female_list.append(name[0])\n",
    "\t\texcept:\n",
    "\t\t    new_female_list.append(name[0])\n",
    "\t\t    \n",
    "\t#print \"Total number of Female Names after is %d.\" %len(new_female_list)\n",
    "\t\n",
    "\t#find_gender_from_first_name('Harsh')\n",
    "\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Link of Profile Picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getProfilePicLink(html):\n",
    "       \n",
    "    soup=BeautifulSoup(html,\"lxml\") \n",
    "    images = [x for x in soup.find_all('img')]\n",
    "    #print images\n",
    "    try:\n",
    "        if \"shrinknp_200_200\" in str(images[0]):\n",
    "            imageUrlString = str(images[0]).replace(\"shrinknp_200_200\", \"shrinknp_400_400\")\n",
    "        else:\n",
    "            imageUrlString = \"\"\n",
    "    except:\n",
    "        imageUrlString = \"\"\n",
    "    \n",
    "    #print imageUrlString\n",
    "    \n",
    "    return imageUrlString"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store Profile Picture to Local Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def storeProfilePicture(profileUrl,profile_link):\n",
    "    \n",
    "    lst = profileUrl.split()\n",
    "    userId = profile_link.split('/')[-1]\n",
    "    regex=re.compile(r'(src).*')\n",
    "    img_url = re.sub('src=','', \"\".join([m.group(0) for l in lst for m in [regex.search(l)] if m]))\n",
    "    img_url = img_url.strip('\"\"')\n",
    "    #print img_url\n",
    "    if img_url:\n",
    "        urllib.urlretrieve(img_url, \"Images/\" + userId + \".jpg\")\n",
    "        print userId + \".jpg is saved.\"\n",
    "        return img_url\n",
    "    else:\n",
    "        with open('ghost_person.png', 'rb') as f:\n",
    "            data = f.read()\n",
    "\n",
    "        with open(\"Images/\" + userId + \".png\", 'wb') as f:\n",
    "            f.write(data)\n",
    "\n",
    "        print userId + \".png is saved.\"\n",
    "        return \"https://static.licdn.com/scds/common/u/images/themes/katy/ghosts/person/ghost_person_100x100_v1.png\".strip(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrap the UserID from Recommended Users' list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getRecommendedUserIds(html):\n",
    "    \n",
    "    \n",
    "    soup=BeautifulSoup(html,\"lxml\")\n",
    "    #content = driver.page_source\n",
    "    #images = [x for x in soup.find_all('img')]\n",
    "    profLinks = [x for x in soup.find_all('li',{'class': 'profile-card'})]\n",
    "    \n",
    "    recUserIds = []\n",
    "    #print profLinks\n",
    "    for link in profLinks:\n",
    "        urls = re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', str(link))\n",
    "        recId = urls[0].split('?')[0].split('/')[-1]\n",
    "        recUserIds.append(recId)\n",
    "    \n",
    "    return recUserIds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Full Name from title in source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getName(html):\n",
    "    \n",
    "    soup=BeautifulSoup(html,\"lxml\")\n",
    "    title = soup.find('title')\n",
    "    name = str(title).replace('<title>','')\n",
    "    full_name = name.replace(' | LinkedIn</title>','')\n",
    "    \n",
    "    return full_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get All Bachelor Degree List and Make a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getBachelorList():\n",
    "\n",
    "    BachelorDict = {}\n",
    "    regex = re.compile('[^a-zA-Z/]')\n",
    "    with open('bachelor_degrees.txt') as fp:\n",
    "        for line in fp.readlines():\n",
    "            lineSepator = line.split('(')\n",
    "            abbr = regex.sub('', lineSepator[1])\n",
    "            abbr = abbr.split('/')\n",
    "            for abrv in abbr:\n",
    "                BachelorDict[abrv] = lineSepator[0].strip()\n",
    "        fp.close()\n",
    "\n",
    "    return BachelorDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Age from Bachelor Degree Starting Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_age(bachelor_year):\n",
    "    today = date.today()\n",
    "    return today.year - bachelor_year + 18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Person's All Degrees and their Duration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_Degree_Duration(html):\n",
    "    \n",
    "    soup=BeautifulSoup(html.encode(\"ascii\",\"ignore\"),\"lxml\")\n",
    "    schoolLinks = soup.find_all('li',{'class':'school'})\n",
    "    degreeList = []\n",
    "    time_range_list = []\n",
    "    \n",
    "    for soup1 in schoolLinks:\n",
    "\n",
    "        degreeLink = soup1.find('span',{'data-field-name':\"Education.DegreeName\"})\n",
    "        timeRange = soup1.find('span',{'class':\"date-range\"})\n",
    "\n",
    "        tempDegree = str(degreeLink).replace('<span class=\"translated translation\" data-field-name=\"Education.DegreeName\">','')\n",
    "        degree = tempDegree.replace('</span>','')\n",
    "\n",
    "        tempTime = str(timeRange).replace('<span class=\"date-range\">','')\n",
    "        time = tempTime.replace('<time>','')\n",
    "        temp_time = time.replace('</time>','')\n",
    "        time_range = temp_time.replace('</span>','')\n",
    "\n",
    "        degreeList.append(degree)\n",
    "        time_range_list.append(time_range)\n",
    "    \n",
    "    return degreeList,time_range_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the Bachelor Year from Degree List and its Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_bachelor_year(degree_list,time_list):\n",
    "    \n",
    "    bachelor_degree_duration = set()\n",
    "    \n",
    "    BachelorDict = getBachelorList()\n",
    "    \n",
    "    for index,dg in enumerate(degree_list):\n",
    "\n",
    "        for key in BachelorDict.keys():\n",
    "            if key in dg:\n",
    "                bachelor_degree_duration.add(time_list[index])\n",
    "                break\n",
    "\n",
    "        for value in BachelorDict.values():\n",
    "            if value in dg:\n",
    "                bachelor_degree_duration.add(time_list[index])\n",
    "                break\n",
    "        \n",
    "        \n",
    "    #print time_list   \n",
    "    bachelor_degree_duration = list(bachelor_degree_duration)\n",
    "    \n",
    "    #print bachelor_degree_duration[0]\n",
    "    \n",
    "    try:\n",
    "        if bachelor_degree_duration[0] == 'None':\n",
    "            if time_list:\n",
    "                #print time_list\n",
    "                bachelor_year = int(time_list[0].split()[0]) - 5\n",
    "            else:\n",
    "                bachelor_year = None\n",
    "\n",
    "        else:\n",
    "            bachelor_year = int(bachelor_degree_duration[0].split()[0])    \n",
    "    \n",
    "    except:\n",
    "        bachelor_year = None\n",
    "    \n",
    "\n",
    "    return bachelor_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the age from LinkedIn Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def age_from_linkedin_profile(profileUrl):\n",
    "    \n",
    "    try:\n",
    "        degree_list, time_list = get_Degree_Duration(profileUrl)\n",
    "    \n",
    "        refined_degree_list = []\n",
    "        regex = re.compile('[^a-zA-Z\\s+]')\n",
    "\n",
    "        for degree in degree_list:\n",
    "            refined_degree_list.append(regex.sub('',degree))\n",
    "\n",
    "        bachelor_year = find_bachelor_year(refined_degree_list,time_list)\n",
    "        #print bachelor_year\n",
    "\n",
    "        if bachelor_year:\n",
    "            age = calculate_age(bachelor_year)\n",
    "        else:\n",
    "            age = None\n",
    "    \n",
    "    except:\n",
    "        age = None\n",
    "        \n",
    "    return age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "harshparikh1001.jpg is saved.\n",
      "george-kramp-8422581.png is saved.\n",
      "marissamayer.jpg is saved.\n",
      "xulifeng.jpg is saved.\n",
      "ramyamadhihallysreenidhi.jpg is saved.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    directory = \"Images\"\n",
    "    \n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    userIds = [\"harshparikh1001\",\"george-kramp-8422581\",\"marissamayer\",\"xulifeng\",\"ramyamadhihallysreenidhi\"]\n",
    "    \n",
    "    recommended_profile_ids = []\n",
    "    \n",
    "    profileDict = {}\n",
    "    #profiles = []\n",
    "    \n",
    "    output = open(\"linkedin_profiles.pickle\", 'wb')   # Save all profiles as pickle file\n",
    "    \n",
    "    for index,usrid in enumerate(userIds):\n",
    "        \n",
    "        profileUrl = \"https://www.linkedin.com/in/\" + usrid\n",
    "        \n",
    "        driver = webdriver.PhantomJS()\n",
    "        driver.get(profileUrl)\n",
    "        html=driver.page_source\n",
    "        \n",
    "        profileDict[usrid] = {}\n",
    "        profileDict[usrid]['Full_Name'] = getName(html)\n",
    "        profileDict[usrid]['Gender'] = find_gender_from_first_name(getName(html).split()[0])\n",
    "        profileDict[usrid]['Recommended_Ids'] = getRecommendedUserIds(html)\n",
    "        \n",
    "        profilePicUrl = getProfilePicLink(html)\n",
    "        \n",
    "        picUrl = storeProfilePicture(profilePicUrl,profileUrl)\n",
    "        \n",
    "        profileDict[usrid]['Profile_Url'] = picUrl\n",
    "        profileDict[usrid]['age'] = age_from_linkedin_profile(html)\n",
    "        \n",
    "        #time.sleep(5) # delays for 5 seconds\n",
    "    \n",
    "    pickle.dump(profileDict, output,-1)\n",
    "    output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open pickle file and read stuff from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pkl_file = open(\"linkedin_profiles.pickle\",\"rb\")\n",
    "mydict=pickle.load(pkl_file) # errors out here\n",
    "pkl_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'george-kramp-8422581': {'Full_Name': 'George Kramp',\n",
       "  'Gender': 'Male',\n",
       "  'Profile_Url': 'https://static.licdn.com/scds/common/u/images/themes/katy/ghosts/person/ghost_person_100x100_v1.png',\n",
       "  'Recommended_Ids': ['anil-issac-0151775',\n",
       "   'romhild-hoogeveen-049b3b18',\n",
       "   'kris-ropella-312502',\n",
       "   'andrew-tochterman-5b79343',\n",
       "   'srirama-venkataraman-560a0a3',\n",
       "   'howard-li-284709',\n",
       "   'cheryl-fay-lauria-abb83753',\n",
       "   'uma-subramanian-57a3452',\n",
       "   'prasad-rv-1b430a14',\n",
       "   'richardkemkers'],\n",
       "  'age': 43},\n",
       " 'harshparikh1001': {'Full_Name': 'Harsh Parikh',\n",
       "  'Gender': 'Male',\n",
       "  'Profile_Url': 'https://media.licdn.com/mpr/mpr/shrinknp_400_400/AAEAAQAAAAAAAAmGAAAAJDNhZmE5ODljLTZjMDItNGUyNC1iYjYyLWMxYTJiNzE1NmYzNA.jpg',\n",
       "  'Recommended_Ids': ['harshparikh',\n",
       "   'parikhharsh',\n",
       "   'harsh-parikh-83976879',\n",
       "   'parikhharsh86',\n",
       "   'harshparikhhp',\n",
       "   'singhlatika',\n",
       "   'vivek-basavarajappa-81a270b1',\n",
       "   'dktrivedi265',\n",
       "   'shouviksdutta',\n",
       "   'sanketwagh',\n",
       "   'parthshah7',\n",
       "   'kumar-shrestha-a3955b111',\n",
       "   'dpatel0220',\n",
       "   'ramyamadhihallysreenidhi',\n",
       "   'xulifeng'],\n",
       "  'age': 24},\n",
       " 'marissamayer': {'Full_Name': 'Marissa Mayer',\n",
       "  'Gender': 'Female',\n",
       "  'Profile_Url': 'https://media.licdn.com/mpr/mpr/shrinknp_400_400/p/1/000/005/28a/1771ae7.jpg',\n",
       "  'Recommended_Ids': ['linkedinmarissamayer',\n",
       "   'mmcreativ',\n",
       "   'marissa-mayer-485a854b',\n",
       "   'marissa-mayer-19748a8',\n",
       "   'marissa-mayer-56201583',\n",
       "   'jeffweiner08',\n",
       "   'johnfwelch',\n",
       "   'randizuckerberg',\n",
       "   'rbranson',\n",
       "   'mdell',\n",
       "   'saverin',\n",
       "   'mark-cuban-06a0755b',\n",
       "   'williamhgates',\n",
       "   'parkersean',\n",
       "   'ariannahuffington'],\n",
       "  'age': 41},\n",
       " 'ramyamadhihallysreenidhi': {'Full_Name': 'Ramya M Sreenidhi',\n",
       "  'Gender': 'Female',\n",
       "  'Profile_Url': 'https://media.licdn.com/mpr/mpr/shrinknp_400_400/AAEAAQAAAAAAAAl5AAAAJDgzNzJhMmVlLWYyZjUtNDE3OC05MDczLWU3MGI4YTYxZDVmYQ.jpg',\n",
       "  'Recommended_Ids': ['mansimalviya',\n",
       "   'sahana-b-gowda-9b0b8572',\n",
       "   'skavya',\n",
       "   'mallika-k-ruby-on-rails-java-sql-javascript-0b2aba110',\n",
       "   'srishtinegi',\n",
       "   'ndhayalini',\n",
       "   'shashanksworld',\n",
       "   'poojamankani',\n",
       "   'anusha-swamynathan-a49613b2',\n",
       "   'ravalinannuru'],\n",
       "  'age': 30},\n",
       " 'xulifeng': {'Full_Name': 'Lifeng Xu',\n",
       "  'Gender': 'Unknown',\n",
       "  'Profile_Url': 'https://media.licdn.com/mpr/mpr/shrinknp_400_400/AAEAAQAAAAAAAAaBAAAAJDIyZDVmMjAyLTA4ZjQtNGJmNy04MWYwLWNhY2EwMmI5YWM2Nw.jpg',\n",
       "  'Recommended_Ids': ['lifeng%EF%BC%88katherine%EF%BC%89-xu-1742b180',\n",
       "   'lifeng-xu-92398449',\n",
       "   'lifeng-xu-3128203a',\n",
       "   'lifeng-xu-9a02105a',\n",
       "   'lifeng-xu-4538ab109',\n",
       "   'harshparikh1001',\n",
       "   'shiva-kumar-0868aa64',\n",
       "   'dktrivedi265',\n",
       "   'pooja-priyanka-0914a43b',\n",
       "   'andre-johnson-19a634b5',\n",
       "   'sarinair',\n",
       "   'aswinkumarjeevan',\n",
       "   'omar-abu-hijleh-24b63a110',\n",
       "   'ramyamadhihallysreenidhi',\n",
       "   'seanjwallace'],\n",
       "  'age': 25}}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test profile of \"Barbara Corcoran\"\n",
    "\n",
    "https://www.linkedin.com/in/barbaracorcoran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "driver = webdriver.PhantomJS()\n",
    "driver.get(\"https://www.linkedin.com/in/barbaracorcoran\")\n",
    "html3=driver.page_source  \n",
    "#print html\n",
    "soup=BeautifulSoup(html3,\"lxml\") \n",
    "images = [x for x in soup.find_all('img')]\n",
    "#print images\n",
    "try:\n",
    "    if \"shrinknp_200_200\" in str(images[0]):\n",
    "        imageUrlString = str(images[0]).replace(\"shrinknp_200_200\", \"shrinknp_400_400\")\n",
    "    else:\n",
    "        imageUrlString = \"\"\n",
    "except:\n",
    "    imageUrlString = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#imageUrlString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Female'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_gender_from_first_name(getName(html3).split()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print age_from_linkedin_profile(html3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## My Profile and Age\n",
    "\n",
    "https://www.linkedin.com/in/harshparikh1001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "driver = webdriver.PhantomJS()\n",
    "driver.get(\"https://www.linkedin.com/in/harshparikh1001\")\n",
    "html1=driver.page_source  \n",
    "#print html1\n",
    "soup=BeautifulSoup(html1,\"lxml\") \n",
    "images = [x for x in soup.find_all('img')]\n",
    "#print images\n",
    "try:\n",
    "    if \"shrinknp_200_200\" in str(images[0]):\n",
    "        imageUrlString = str(images[0]).replace(\"shrinknp_200_200\", \"shrinknp_400_400\")\n",
    "    else:\n",
    "        imageUrlString = \"\"\n",
    "except:\n",
    "    imageUrlString = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Male'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_gender_from_first_name(getName(html1).split()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_from_linkedin_profile(html1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test profile of \"Satya Nadella\"\n",
    "\n",
    "https://www.linkedin.com/in/satya-nadella-3145136"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "driver = webdriver.PhantomJS()\n",
    "driver.get(\"https://www.linkedin.com/in/satya-nadella-3145136\")\n",
    "html2=driver.page_source  \n",
    "#print html2\n",
    "soup=BeautifulSoup(html2,\"lxml\") \n",
    "images = [x for x in soup.find_all('img')]\n",
    "#print images\n",
    "try:\n",
    "    if \"shrinknp_200_200\" in str(images[0]):\n",
    "        imageUrlString = str(images[0]).replace(\"shrinknp_200_200\", \"shrinknp_400_400\")\n",
    "    else:\n",
    "        imageUrlString = \"\"\n",
    "except:\n",
    "    imageUrlString = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Unknown'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_gender_from_first_name(getName(html2).split()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_from_linkedin_profile(html2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#driver = webdriver.PhantomJS()\n",
    "#driver.get(\"https://www.linkedin.com/in/georgecorliss\")\n",
    "#html=driver.page_source    \n",
    "#soup=BeautifulSoup(html,\"lxml\")\n",
    "#schoolLinks = soup.find_all('li',{'class':'school'})\n",
    "\n",
    "#for soup1 in schoolLinks:\n",
    "    \n",
    "#    degreeLink = soup1.find('span',{'data-field-name':\"Education.DegreeName\"})\n",
    "#    timeRange = soup1.find('span',{'class':\"date-range\"})\n",
    "    \n",
    "#    tempDegree = str(degreeLink).replace('<span class=\"translated translation\" data-field-name=\"Education.DegreeName\">','')\n",
    "#    degree = tempDegree.replace('</span>','')\n",
    "    \n",
    "#    tempTime = str(timeRange).replace('<span class=\"date-range\">','')\n",
    "#    time = tempTime.replace('<time>','')\n",
    "#    temp_time = time.replace('</time>','')\n",
    "#    time_range = temp_time.replace('</span>','')\n",
    "    \n",
    "#    print degree\n",
    "#    print time_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import re\n",
    "#link = re.sub(r'(<a href=\"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\">)','',str(links[3]))\n",
    "#link = link.replace('<ul>',' ')\n",
    "#link = link.replace('</li><li>',' ')\n",
    "#link = link.replace('<li>',' ')\n",
    "#link = link.replace('</a>',' ')\n",
    "#link = link.replace('</li></ul>',' ')\n",
    "#print link.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link to get all profiles with the first Name\n",
    "\n",
    "https://www.linkedin.com/pub/dir/Bill"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
