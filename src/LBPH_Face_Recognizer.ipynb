{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import re\n",
    "import os,sys\n",
    "import time\n",
    "from datetime import date\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except:\n",
    "    import pickle\n",
    "import pprint\n",
    "from collections import deque\n",
    "from shutil import copyfile\n",
    "import random\n",
    "import glob\n",
    "# Import the required modules\n",
    "import cv2, os\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pkl_fl = open(\"linkedin_profiles.pickle\",\"rb\")\n",
    "my_original_list=pickle.load(pkl_fl) # errors out here\n",
    "pkl_fl.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eryn-olson-50328143'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_original_list[0]['User_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fileList = glob.glob(\"./Images/*.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "directory = \"Male\"\n",
    "    \n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "directory1 = \"Female\"\n",
    "\n",
    "if not os.path.exists(directory1):\n",
    "    os.makedirs(directory1)    \n",
    "\n",
    "    \n",
    "for id,fp in enumerate(fileList):\n",
    "    filename, file_extension = os.path.splitext(fp)\n",
    "    uid = filename.split('/')[-1]\n",
    "    #print fp\n",
    "    for prof in my_original_list:\n",
    "        if prof['User_ID'] == uid:\n",
    "            new_file_extension = prof['Gender']\n",
    "            new_file_extension = new_file_extension.title()\n",
    "            #os.rename(fp, filename+\".\"+new_file_extension)\n",
    "            copyfile(filename+\".jpg\", './Lable_Images1/'+ uid + '.' + str(id) + \".\"+new_file_extension+'.jpg')\n",
    "            #copyfile(filename+\".jpg\", new_file_extension +'/'+uid+\".\"+new_file_extension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "for file in os.listdir(\"Lable_Images1\"):\n",
    "    file_path = os.path.join(\"Lable_Images1\", file)\n",
    "    try:\n",
    "        if not file.endswith('.jpg'):\n",
    "            os.unlink(file_path)\n",
    "        #elif os.path.isdir(file_path): shutil.rmtree(file_path)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For face detection we will use the Haar Cascade provided by OpenCV.\n",
    "cascadePath = \"haarcascade_frontalface_default.xml\"\n",
    "faceCascade = cv2.CascadeClassifier(cascadePath)\n",
    "\n",
    "# For face recognition we will the the LBPH Face Recognizer \n",
    "recognizer = cv2.createLBPHFaceRecognizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_images_and_labels(path):\n",
    "    # Append all the absolute image paths in a list image_paths\n",
    "    # We will not read the image with the .sad extension in the training set\n",
    "    # Rather, we will use them to test our accuracy of the training\n",
    "    image_paths = [os.path.join(path, f) for f in os.listdir(path)]\n",
    "    # images will contains face images\n",
    "    images = []\n",
    "    # labels will contains the label that is assigned to the image\n",
    "    labels = []\n",
    "    #gender will contains 1 or 0 indecating male or female\n",
    "    gender =[]\n",
    "    for image_path in image_paths:\n",
    "        # Read the image and convert to grayscale\n",
    "        try:\n",
    "            image_pil = Image.open(image_path).convert('L')\n",
    "            # Convert the image format into numpy array\n",
    "            image = np.array(image_pil, 'uint8')\n",
    "            # Get the label of the image\n",
    "        except:\n",
    "            pass\n",
    "        #print image_path\n",
    "        \n",
    "        \n",
    "        nbr = int(os.path.split(image_path)[1].split(\".\")[1])\n",
    "        gender_current = os.path.split(image_path)[1].split(\".\")[2]\n",
    "        print nbr\n",
    "        \n",
    "        # Detect the face in the image\n",
    "        faces = faceCascade.detectMultiScale(image)\n",
    "        # If face is detected, append the face to images and the label to labels\n",
    "        for (x, y, w, h) in faces:\n",
    "            images.append(image[y: y + h, x: x + w])\n",
    "            labels.append(nbr)\n",
    "            gender.append(gender_current)\n",
    "            \n",
    "            cv2.imshow(\"Adding faces to traning set...\", image[y: y + h, x: x + w])\n",
    "            cv2.waitKey(50)\n",
    "    # return the images list and labels list\n",
    "    print(\"lables\")\n",
    "    print(labels)\n",
    "    print(\"gender_current\")\n",
    "    print(gender)\n",
    "    \n",
    "    return images, labels, gender\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def image_prediction(image_path):   #comparing the image in image_path to the data base\n",
    "    \n",
    "    print(image_path)\n",
    "    counter_above=0\n",
    "    counter_correct=0\n",
    "    \n",
    "    found_flag=0\n",
    "    predict_image_pil = Image.open(image_path).convert('L')\n",
    "    predict_image = np.array(predict_image_pil, 'uint8')\n",
    "    faces = faceCascade.detectMultiScale(predict_image)\n",
    "\n",
    "    print(faces)\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        nbr_predicted, conf = recognizer.predict(predict_image[y: y + h, x: x + w])\n",
    "        nbr_actual = os.path.split(image_path)[1].split(\".\")[0]\n",
    "            \n",
    "        if nbr_actual == nbr_predicted:\n",
    "            print \"{} is Correctly Recognized with confidence {}\".format(nbr_actual, conf)\n",
    "            cv2.imshow(\"Recognizing Face\", predict_image[y: y + h, x: x + w])\n",
    "            cv2.waitKey(1000)\n",
    "            found_flag=1;\n",
    "            counter_correct=counter_correct+1\n",
    "\n",
    "            if conf >= 50:\n",
    "                counter_above=counter_above+1\n",
    "            break\n",
    "        else:\n",
    "            print \"{} is Incorrect Recognized as {}\".format(nbr_actual, nbr_predicted)\n",
    "        \n",
    "    if found_flag == 0:\n",
    "        print('new image')\n",
    "        \n",
    "    return nbr_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1076\n",
      "378\n",
      "363\n",
      "750\n",
      "1100\n",
      "427\n",
      "470\n",
      "578\n",
      "1083\n",
      "580\n",
      "170\n",
      "205\n",
      "831\n",
      "1153\n",
      "501\n",
      "184\n",
      "607\n",
      "782\n",
      "919\n",
      "1119\n",
      "70\n",
      "693\n",
      "1105\n",
      "906\n",
      "190\n",
      "497\n",
      "1127\n",
      "938\n",
      "271\n",
      "688\n",
      "116\n",
      "473\n",
      "949\n",
      "30\n",
      "1045\n",
      "60\n",
      "110\n",
      "433\n",
      "380\n",
      "100\n",
      "1081\n",
      "913\n",
      "1116\n",
      "971\n",
      "429\n",
      "12\n",
      "18\n",
      "889\n",
      "230\n",
      "920\n",
      "lables\n",
      "[378, 378, 363, 750, 1100, 1100, 427, 470, 578, 1083, 580, 170, 205, 831, 1153, 1153, 501, 184, 607, 782, 782, 919, 1119, 70, 693, 1105, 906, 190, 190, 497, 497, 497, 1127, 938, 271, 271, 688, 116, 473, 949, 30, 1045, 1045, 60, 110, 433, 433, 380, 380, 100, 1081, 913, 1116, 971, 429, 12, 12, 889, 230, 920]\n",
      "gender_current\n",
      "['Male', 'Male', 'Male', 'Male', 'Male', 'Male', 'Male', 'Male', 'Female', 'Female', 'Male', 'Female', 'Female', 'Male', 'Female', 'Female', 'Male', 'Female', 'Female', 'Male', 'Male', 'Female', 'Female', 'Male', 'Female', 'Female', 'Female', 'Male', 'Male', 'Male', 'Male', 'Male', 'Female', 'Male', 'Female', 'Female', 'Female', 'Male', 'Male', 'Male', 'Male', 'Male', 'Male', 'Male', 'Male', 'Male', 'Male', 'Female', 'Female', 'Female', 'Male', 'Male', 'Male', 'Female', 'Male', 'Male', 'Male', 'Female', 'Male', 'Male']\n",
      "ankitanarula.jpg\n",
      "[[129  68 157 157]]\n",
      "ankitanarula is Incorrect Recognized as 919\n",
      "new image\n",
      "('gender number is %d', 919)\n",
      "female\n"
     ]
    }
   ],
   "source": [
    "images, labels, gender = get_images_and_labels('Lable_Images1')\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "recognizer.train(images, np.array(labels))\n",
    "\n",
    "image_path = 'ankitanarula.jpg'\n",
    "nbr_predicted = image_prediction(image_path)\n",
    "\n",
    "print(\"gender number is %d\", nbr_predicted)\n",
    "counter=0\n",
    "\n",
    "\n",
    "for f in labels:\n",
    " \n",
    "    if f==nbr_predicted:\n",
    "        current_gender=gender[counter]\n",
    "        break\n",
    "    counter=counter+1 \n",
    "\n",
    "if current_gender == 'Male':\n",
    "    print('male')\n",
    "if current_gender == 'Female':\n",
    "    print('female')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
